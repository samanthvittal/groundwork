# P0.1 Infrastructure Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Set up the foundational infrastructure for Groundwork including project structure, FastAPI app, database, Docker, CI/CD, and testing.

**Architecture:** Domain-based module organization in src layout. Fully async PostgreSQL with SQLAlchemy 2.0. FastAPI app factory pattern with structured JSON logging. Full containerized development with hot-reload.

**Tech Stack:** Python 3.12, FastAPI 0.128.0, SQLAlchemy 2.0.45, asyncpg, PostgreSQL 16, Docker, GitHub Actions, uv, Ruff, mypy

**Design Doc:** `docs/plans/2026-01-18-p0.1-infrastructure-design.md`

---

## Task 1: Project Bootstrap

**Files:**
- Create: `pyproject.toml`
- Create: `src/groundwork/__init__.py`
- Create: `tests/__init__.py`
- Create: `.env.example`

**Step 1: Create pyproject.toml**

```toml
[project]
name = "groundwork"
version = "0.1.0"
description = "Open source self-hosted project management"
readme = "README.md"
license = { text = "GPL-3.0" }
requires-python = ">=3.12"
dependencies = [
    "fastapi>=0.128.0",
    "uvicorn[standard]>=0.40.0",
    "pydantic>=2.12.5",
    "pydantic-settings>=2.7.0",
    "sqlalchemy[asyncio]>=2.0.45",
    "asyncpg>=0.30.0",
    "alembic>=1.14.0",
    "python-jose[cryptography]>=3.3.0",
    "passlib[argon2]>=1.7.4",
]

[project.optional-dependencies]
dev = [
    "pytest>=8.3.0",
    "pytest-asyncio>=0.25.0",
    "pytest-cov>=6.0.0",
    "httpx>=0.28.0",
    "factory-boy>=3.3.0",
    "ruff>=0.9.0",
    "mypy>=1.14.0",
    "pre-commit>=4.0.0",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["src/groundwork"]

[tool.pytest.ini_options]
asyncio_mode = "auto"
testpaths = ["tests"]
asyncio_default_fixture_loop_scope = "function"

[tool.ruff]
target-version = "py312"
line-length = 88
src = ["src", "tests"]

[tool.ruff.lint]
select = ["E", "F", "I", "UP", "B", "SIM", "ASYNC"]
ignore = ["E501"]

[tool.mypy]
python_version = "3.12"
strict = true
plugins = ["pydantic.mypy"]

[[tool.mypy.overrides]]
module = "tests.*"
disallow_untyped_defs = false
```

**Step 2: Create package init files**

Create `src/groundwork/__init__.py`:
```python
"""Groundwork - Open source self-hosted project management."""

__version__ = "0.1.0"
```

Create `tests/__init__.py`:
```python
"""Test suite for Groundwork."""
```

**Step 3: Create .env.example**

```bash
# Database
DATABASE_URL=postgresql+asyncpg://groundwork:groundwork@db:5432/groundwork

# Security
SECRET_KEY=change-me-in-production

# Application
ENVIRONMENT=development
DEBUG=true
LOG_LEVEL=DEBUG
```

**Step 4: Initialize uv and install dependencies**

Run: `uv sync`
Expected: Dependencies installed, uv.lock created

**Step 5: Commit**

```bash
git add pyproject.toml uv.lock src/ tests/ .env.example
git commit -m "feat: bootstrap project with uv and dependencies"
```

---

## Task 2: Configuration Module

**Files:**
- Create: `src/groundwork/core/__init__.py`
- Create: `src/groundwork/core/config.py`
- Create: `tests/core/__init__.py`
- Create: `tests/core/test_config.py`

**Step 1: Write the failing test**

Create `tests/core/__init__.py`:
```python
"""Tests for core module."""
```

Create `tests/core/test_config.py`:
```python
"""Tests for configuration module."""

import os

import pytest


def test_settings_loads_from_env(monkeypatch: pytest.MonkeyPatch) -> None:
    """Settings should load values from environment variables."""
    monkeypatch.setenv("DATABASE_URL", "postgresql+asyncpg://test:test@localhost:5432/test")
    monkeypatch.setenv("SECRET_KEY", "test-secret")
    monkeypatch.setenv("ENVIRONMENT", "testing")
    monkeypatch.setenv("DEBUG", "false")

    # Clear the cache to force reload
    from groundwork.core.config import get_settings

    get_settings.cache_clear()
    settings = get_settings()

    assert str(settings.database_url) == "postgresql+asyncpg://test:test@localhost:5432/test"
    assert settings.secret_key == "test-secret"
    assert settings.environment == "testing"
    assert settings.debug is False


def test_settings_has_defaults(monkeypatch: pytest.MonkeyPatch) -> None:
    """Settings should have sensible defaults."""
    monkeypatch.setenv("DATABASE_URL", "postgresql+asyncpg://test:test@localhost:5432/test")
    monkeypatch.setenv("SECRET_KEY", "test-secret")

    from groundwork.core.config import get_settings

    get_settings.cache_clear()
    settings = get_settings()

    assert settings.app_name == "Groundwork"
    assert settings.db_pool_size == 5
    assert settings.access_token_expire_minutes == 30


def test_settings_is_cached(monkeypatch: pytest.MonkeyPatch) -> None:
    """get_settings should return cached instance."""
    monkeypatch.setenv("DATABASE_URL", "postgresql+asyncpg://test:test@localhost:5432/test")
    monkeypatch.setenv("SECRET_KEY", "test-secret")

    from groundwork.core.config import get_settings

    get_settings.cache_clear()
    settings1 = get_settings()
    settings2 = get_settings()

    assert settings1 is settings2
```

**Step 2: Run test to verify it fails**

Run: `uv run pytest tests/core/test_config.py -v`
Expected: FAIL with ModuleNotFoundError

**Step 3: Write the implementation**

Create `src/groundwork/core/__init__.py`:
```python
"""Core infrastructure module."""

from groundwork.core.config import Settings, get_settings

__all__ = ["Settings", "get_settings"]
```

Create `src/groundwork/core/config.py`:
```python
"""Application configuration using Pydantic Settings."""

from functools import lru_cache

from pydantic import PostgresDsn
from pydantic_settings import BaseSettings, SettingsConfigDict


class Settings(BaseSettings):
    """Application settings loaded from environment variables."""

    model_config = SettingsConfigDict(
        env_file=".env",
        env_file_encoding="utf-8",
        case_sensitive=False,
    )

    # Application
    app_name: str = "Groundwork"
    debug: bool = False
    environment: str = "development"

    # Database
    database_url: PostgresDsn
    db_pool_size: int = 5
    db_max_overflow: int = 10

    # Security
    secret_key: str
    access_token_expire_minutes: int = 30

    # Logging
    log_level: str = "INFO"
    log_json: bool = True


@lru_cache
def get_settings() -> Settings:
    """Get cached settings instance."""
    return Settings()
```

**Step 4: Run test to verify it passes**

Run: `uv run pytest tests/core/test_config.py -v`
Expected: PASS (3 tests)

**Step 5: Run type check**

Run: `uv run mypy src/groundwork/core/config.py`
Expected: Success

**Step 6: Commit**

```bash
git add src/groundwork/core/ tests/core/
git commit -m "feat: add configuration module with Pydantic Settings"
```

---

## Task 3: Structured JSON Logging

**Files:**
- Create: `src/groundwork/core/logging.py`
- Create: `tests/core/test_logging.py`

**Step 1: Write the failing test**

Create `tests/core/test_logging.py`:
```python
"""Tests for logging module."""

import json
import logging

import pytest


def test_json_formatter_formats_as_json() -> None:
    """JSONFormatter should output valid JSON."""
    from groundwork.core.logging import JSONFormatter

    formatter = JSONFormatter()
    record = logging.LogRecord(
        name="test",
        level=logging.INFO,
        pathname="test.py",
        lineno=1,
        msg="Test message",
        args=(),
        exc_info=None,
    )

    output = formatter.format(record)
    parsed = json.loads(output)

    assert parsed["level"] == "INFO"
    assert parsed["logger"] == "test"
    assert parsed["message"] == "Test message"
    assert "timestamp" in parsed


def test_json_formatter_includes_extra_fields() -> None:
    """JSONFormatter should include extra fields in output."""
    from groundwork.core.logging import JSONFormatter

    formatter = JSONFormatter()
    record = logging.LogRecord(
        name="test",
        level=logging.INFO,
        pathname="test.py",
        lineno=1,
        msg="Test message",
        args=(),
        exc_info=None,
    )
    record.user_id = 42
    record.request_id = "abc123"

    output = formatter.format(record)
    parsed = json.loads(output)

    assert parsed["user_id"] == 42
    assert parsed["request_id"] == "abc123"


def test_get_logger_returns_logger() -> None:
    """get_logger should return a Logger instance."""
    from groundwork.core.logging import get_logger

    logger = get_logger("test.module")

    assert isinstance(logger, logging.Logger)
    assert logger.name == "test.module"
```

**Step 2: Run test to verify it fails**

Run: `uv run pytest tests/core/test_logging.py -v`
Expected: FAIL with ModuleNotFoundError

**Step 3: Write the implementation**

Create `src/groundwork/core/logging.py`:
```python
"""Structured JSON logging setup."""

import json
import logging
import sys
from datetime import datetime, timezone
from typing import Any


class JSONFormatter(logging.Formatter):
    """Format log records as JSON."""

    # Fields to exclude from extra data
    EXCLUDE_FIELDS = frozenset({
        "name", "msg", "args", "created", "filename", "funcName",
        "levelname", "levelno", "lineno", "module", "msecs", "pathname",
        "process", "processName", "relativeCreated", "stack_info",
        "exc_info", "exc_text", "thread", "threadName", "taskName", "message",
    })

    def format(self, record: logging.LogRecord) -> str:
        """Format a log record as JSON."""
        log_data: dict[str, Any] = {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
        }

        # Include extra fields
        for key, value in record.__dict__.items():
            if key not in self.EXCLUDE_FIELDS:
                log_data[key] = value

        if record.exc_info:
            log_data["exception"] = self.formatException(record.exc_info)

        return json.dumps(log_data)


def setup_logging(level: str = "INFO") -> None:
    """Configure application logging."""
    handler = logging.StreamHandler(sys.stdout)
    handler.setFormatter(JSONFormatter())

    logging.basicConfig(
        level=getattr(logging, level.upper()),
        handlers=[handler],
        force=True,
    )

    # Quiet noisy libraries
    logging.getLogger("uvicorn.access").setLevel(logging.WARNING)
    logging.getLogger("httpx").setLevel(logging.WARNING)


def get_logger(name: str) -> logging.Logger:
    """Get a logger instance."""
    return logging.getLogger(name)
```

**Step 4: Update core __init__.py**

Edit `src/groundwork/core/__init__.py`:
```python
"""Core infrastructure module."""

from groundwork.core.config import Settings, get_settings
from groundwork.core.logging import get_logger, setup_logging

__all__ = ["Settings", "get_settings", "get_logger", "setup_logging"]
```

**Step 5: Run test to verify it passes**

Run: `uv run pytest tests/core/test_logging.py -v`
Expected: PASS (3 tests)

**Step 6: Run type check**

Run: `uv run mypy src/groundwork/core/logging.py`
Expected: Success

**Step 7: Commit**

```bash
git add src/groundwork/core/ tests/core/test_logging.py
git commit -m "feat: add structured JSON logging"
```

---

## Task 4: Database Module

**Files:**
- Create: `src/groundwork/core/database.py`
- Create: `tests/core/test_database.py`

**Step 1: Write the failing test**

Create `tests/core/test_database.py`:
```python
"""Tests for database module."""

import pytest


def test_base_class_exists() -> None:
    """Base declarative class should be importable."""
    from groundwork.core.database import Base

    assert Base is not None
    assert hasattr(Base, "metadata")


def test_get_db_is_async_generator() -> None:
    """get_db should be an async generator function."""
    import inspect

    from groundwork.core.database import get_db

    assert inspect.isasyncgenfunction(get_db)
```

**Step 2: Run test to verify it fails**

Run: `uv run pytest tests/core/test_database.py -v`
Expected: FAIL with ModuleNotFoundError

**Step 3: Write the implementation**

Create `src/groundwork/core/database.py`:
```python
"""Database configuration and session management."""

from collections.abc import AsyncGenerator

from sqlalchemy.ext.asyncio import (
    AsyncSession,
    async_sessionmaker,
    create_async_engine,
)
from sqlalchemy.orm import DeclarativeBase

from groundwork.core.config import get_settings


class Base(DeclarativeBase):
    """Base class for all SQLAlchemy models."""

    pass


def _create_engine() -> tuple:
    """Create database engine and session factory."""
    settings = get_settings()

    engine = create_async_engine(
        str(settings.database_url),
        pool_size=settings.db_pool_size,
        max_overflow=settings.db_max_overflow,
        echo=settings.debug,
    )

    session_factory = async_sessionmaker(
        engine,
        class_=AsyncSession,
        expire_on_commit=False,
    )

    return engine, session_factory


# Lazy initialization - created on first use
_engine = None
_async_session_factory = None


def get_engine():
    """Get the database engine, creating it if needed."""
    global _engine, _async_session_factory
    if _engine is None:
        _engine, _async_session_factory = _create_engine()
    return _engine


def get_session_factory():
    """Get the session factory, creating it if needed."""
    global _engine, _async_session_factory
    if _async_session_factory is None:
        _engine, _async_session_factory = _create_engine()
    return _async_session_factory


async def get_db() -> AsyncGenerator[AsyncSession, None]:
    """Dependency for FastAPI routes to get database session."""
    session_factory = get_session_factory()
    async with session_factory() as session:
        try:
            yield session
            await session.commit()
        except Exception:
            await session.rollback()
            raise
```

**Step 4: Update core __init__.py**

Edit `src/groundwork/core/__init__.py`:
```python
"""Core infrastructure module."""

from groundwork.core.config import Settings, get_settings
from groundwork.core.database import Base, get_db, get_engine
from groundwork.core.logging import get_logger, setup_logging

__all__ = [
    "Base",
    "Settings",
    "get_db",
    "get_engine",
    "get_logger",
    "get_settings",
    "setup_logging",
]
```

**Step 5: Run test to verify it passes**

Run: `uv run pytest tests/core/test_database.py -v`
Expected: PASS (2 tests)

**Step 6: Run type check**

Run: `uv run mypy src/groundwork/core/database.py`
Expected: Success

**Step 7: Commit**

```bash
git add src/groundwork/core/ tests/core/test_database.py
git commit -m "feat: add async database module with SQLAlchemy 2.0"
```

---

## Task 5: Health Check Service

**Files:**
- Create: `src/groundwork/health/__init__.py`
- Create: `src/groundwork/health/services.py`
- Create: `tests/health/__init__.py`
- Create: `tests/health/test_services.py`

**Step 1: Write the failing test**

Create `tests/health/__init__.py`:
```python
"""Tests for health module."""
```

Create `tests/health/test_services.py`:
```python
"""Tests for health services."""

from unittest.mock import AsyncMock, MagicMock

import pytest


@pytest.mark.asyncio
async def test_check_readiness_returns_true_when_db_connected() -> None:
    """check_readiness should return True when database is accessible."""
    from groundwork.health.services import HealthService

    mock_session = AsyncMock()
    mock_session.execute = AsyncMock(return_value=MagicMock())

    service = HealthService(mock_session)
    result = await service.check_readiness()

    assert result is True
    mock_session.execute.assert_called_once()


@pytest.mark.asyncio
async def test_check_readiness_returns_false_on_db_error() -> None:
    """check_readiness should return False when database is not accessible."""
    from groundwork.health.services import HealthService

    mock_session = AsyncMock()
    mock_session.execute = AsyncMock(side_effect=Exception("Connection failed"))

    service = HealthService(mock_session)
    result = await service.check_readiness()

    assert result is False


@pytest.mark.asyncio
async def test_get_details_returns_status_info() -> None:
    """get_details should return status and component info."""
    from groundwork.health.services import HealthService

    mock_session = AsyncMock()
    mock_session.execute = AsyncMock(return_value=MagicMock())

    service = HealthService(mock_session)
    result = await service.get_details()

    assert "status" in result
    assert "version" in result
    assert "environment" in result
    assert "components" in result
    assert "database" in result["components"]
```

**Step 2: Run test to verify it fails**

Run: `uv run pytest tests/health/test_services.py -v`
Expected: FAIL with ModuleNotFoundError

**Step 3: Write the implementation**

Create `src/groundwork/health/__init__.py`:
```python
"""Health check module."""

from groundwork.health.services import HealthService

__all__ = ["HealthService"]
```

Create `src/groundwork/health/services.py`:
```python
"""Health check services."""

from sqlalchemy import text
from sqlalchemy.ext.asyncio import AsyncSession

from groundwork.core.config import get_settings


class HealthService:
    """Service for performing health checks."""

    def __init__(self, db: AsyncSession) -> None:
        """Initialize health service with database session."""
        self.db = db
        self.settings = get_settings()

    async def check_readiness(self) -> bool:
        """Check if application is ready to serve traffic."""
        try:
            await self.db.execute(text("SELECT 1"))
            return True
        except Exception:
            return False

    async def get_details(self) -> dict:
        """Get detailed health information."""
        db_ok = await self.check_readiness()
        return {
            "status": "ok" if db_ok else "degraded",
            "version": "0.1.0",
            "environment": self.settings.environment,
            "components": {
                "database": {"status": "ok" if db_ok else "unavailable"},
            },
        }
```

**Step 4: Run test to verify it passes**

Run: `uv run pytest tests/health/test_services.py -v`
Expected: PASS (3 tests)

**Step 5: Run type check**

Run: `uv run mypy src/groundwork/health/`
Expected: Success

**Step 6: Commit**

```bash
git add src/groundwork/health/ tests/health/
git commit -m "feat: add health check service"
```

---

## Task 6: Health Check Routes

**Files:**
- Create: `src/groundwork/health/routes.py`
- Create: `src/groundwork/health/schemas.py`
- Modify: `src/groundwork/health/__init__.py`
- Create: `tests/health/test_routes.py`

**Step 1: Write the failing test**

Create `tests/health/test_routes.py`:
```python
"""Tests for health routes."""

import pytest
from httpx import ASGITransport, AsyncClient


@pytest.mark.asyncio
async def test_liveness_returns_ok() -> None:
    """GET /health/live should return status ok."""
    from groundwork.health.routes import router
    from fastapi import FastAPI

    app = FastAPI()
    app.include_router(router, prefix="/health")

    async with AsyncClient(
        transport=ASGITransport(app=app),
        base_url="http://test"
    ) as client:
        response = await client.get("/health/live")

    assert response.status_code == 200
    assert response.json() == {"status": "ok"}
```

**Step 2: Run test to verify it fails**

Run: `uv run pytest tests/health/test_routes.py::test_liveness_returns_ok -v`
Expected: FAIL with ModuleNotFoundError

**Step 3: Write the implementation**

Create `src/groundwork/health/schemas.py`:
```python
"""Health check schemas."""

from pydantic import BaseModel


class HealthStatus(BaseModel):
    """Basic health status response."""

    status: str


class ComponentStatus(BaseModel):
    """Individual component status."""

    status: str


class HealthDetails(BaseModel):
    """Detailed health response."""

    status: str
    version: str
    environment: str
    components: dict[str, ComponentStatus]
```

Create `src/groundwork/health/routes.py`:
```python
"""Health check API routes."""

from fastapi import APIRouter, Depends, Response
from sqlalchemy.ext.asyncio import AsyncSession

from groundwork.core.database import get_db
from groundwork.health.schemas import HealthDetails, HealthStatus
from groundwork.health.services import HealthService

router = APIRouter()


@router.get("/live", response_model=HealthStatus)
async def liveness() -> HealthStatus:
    """Liveness probe - app is running."""
    return HealthStatus(status="ok")


@router.get("/ready", response_model=HealthStatus)
async def readiness(
    response: Response,
    db: AsyncSession = Depends(get_db),
) -> HealthStatus:
    """Readiness probe - app is ready to serve traffic."""
    service = HealthService(db)
    is_ready = await service.check_readiness()
    if not is_ready:
        response.status_code = 503
        return HealthStatus(status="unavailable")
    return HealthStatus(status="ok")


@router.get("/details", response_model=HealthDetails)
async def details(db: AsyncSession = Depends(get_db)) -> HealthDetails:
    """Detailed health information."""
    service = HealthService(db)
    details_dict = await service.get_details()
    return HealthDetails(**details_dict)
```

Update `src/groundwork/health/__init__.py`:
```python
"""Health check module."""

from groundwork.health.routes import router
from groundwork.health.services import HealthService

__all__ = ["HealthService", "router"]
```

**Step 4: Run test to verify it passes**

Run: `uv run pytest tests/health/test_routes.py::test_liveness_returns_ok -v`
Expected: PASS

**Step 5: Run type check**

Run: `uv run mypy src/groundwork/health/`
Expected: Success

**Step 6: Commit**

```bash
git add src/groundwork/health/ tests/health/test_routes.py
git commit -m "feat: add health check routes"
```

---

## Task 7: FastAPI Application

**Files:**
- Create: `src/groundwork/main.py`
- Create: `tests/test_main.py`

**Step 1: Write the failing test**

Create `tests/test_main.py`:
```python
"""Tests for main application."""

import pytest
from httpx import ASGITransport, AsyncClient


@pytest.mark.asyncio
async def test_create_app_returns_fastapi_instance() -> None:
    """create_app should return a FastAPI application."""
    from fastapi import FastAPI

    from groundwork.main import create_app

    app = create_app()

    assert isinstance(app, FastAPI)
    assert app.title == "Groundwork"


@pytest.mark.asyncio
async def test_health_live_endpoint_accessible() -> None:
    """Health live endpoint should be accessible."""
    from groundwork.main import create_app

    app = create_app()

    async with AsyncClient(
        transport=ASGITransport(app=app),
        base_url="http://test"
    ) as client:
        response = await client.get("/health/live")

    assert response.status_code == 200


@pytest.mark.asyncio
async def test_request_id_middleware_adds_header() -> None:
    """Request ID middleware should add X-Request-ID header."""
    from groundwork.main import create_app

    app = create_app()

    async with AsyncClient(
        transport=ASGITransport(app=app),
        base_url="http://test"
    ) as client:
        response = await client.get("/health/live")

    assert "x-request-id" in response.headers
```

**Step 2: Run test to verify it fails**

Run: `uv run pytest tests/test_main.py -v`
Expected: FAIL with ModuleNotFoundError

**Step 3: Write the implementation**

Create `src/groundwork/main.py`:
```python
"""FastAPI application factory."""

import uuid
from contextlib import asynccontextmanager
from typing import AsyncGenerator

from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware

from groundwork.core.config import get_settings
from groundwork.core.database import get_engine
from groundwork.core.logging import get_logger, setup_logging
from groundwork.health.routes import router as health_router

logger = get_logger(__name__)


@asynccontextmanager
async def lifespan(app: FastAPI) -> AsyncGenerator[None, None]:
    """Application lifespan - startup and shutdown events."""
    settings = get_settings()
    logger.info(
        "Starting Groundwork",
        extra={"version": app.version, "environment": settings.environment},
    )
    yield
    engine = get_engine()
    await engine.dispose()
    logger.info("Shutting down Groundwork")


def create_app() -> FastAPI:
    """Create and configure the FastAPI application."""
    settings = get_settings()
    setup_logging(settings.log_level)

    app = FastAPI(
        title=settings.app_name,
        version="0.1.0",
        lifespan=lifespan,
        docs_url="/docs" if settings.debug else None,
        redoc_url="/redoc" if settings.debug else None,
    )

    # CORS middleware
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"] if settings.debug else [],
        allow_methods=["*"],
        allow_headers=["*"],
    )

    # Request ID middleware
    @app.middleware("http")
    async def request_id_middleware(request: Request, call_next):
        request_id = request.headers.get("X-Request-ID", str(uuid.uuid4()))
        request.state.request_id = request_id
        response = await call_next(request)
        response.headers["X-Request-ID"] = request_id
        return response

    # Include routers
    app.include_router(health_router, prefix="/health", tags=["health"])

    return app


# Application instance for uvicorn
app = create_app()
```

**Step 4: Run test to verify it passes**

Run: `uv run pytest tests/test_main.py -v`
Expected: PASS (3 tests)

**Step 5: Run type check**

Run: `uv run mypy src/groundwork/main.py`
Expected: Success

**Step 6: Commit**

```bash
git add src/groundwork/main.py tests/test_main.py
git commit -m "feat: add FastAPI application factory with middleware"
```

---

## Task 8: Alembic Setup

**Files:**
- Create: `alembic.ini`
- Create: `alembic/env.py`
- Create: `alembic/versions/.gitkeep`
- Create: `alembic/script.py.mako`

**Step 1: Create alembic.ini**

```ini
[alembic]
script_location = alembic
prepend_sys_path = .
version_path_separator = os

[post_write_hooks]

[loggers]
keys = root,sqlalchemy,alembic

[handlers]
keys = console

[formatters]
keys = generic

[logger_root]
level = WARN
handlers = console
qualname =

[logger_sqlalchemy]
level = WARN
handlers =
qualname = sqlalchemy.engine

[logger_alembic]
level = INFO
handlers =
qualname = alembic

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s
datefmt = %H:%M:%S
```

**Step 2: Create alembic directory structure**

Run: `mkdir -p alembic/versions`

Create `alembic/versions/.gitkeep`:
```
```

**Step 3: Create alembic/script.py.mako**

```mako
"""${message}

Revision ID: ${up_revision}
Revises: ${down_revision | comma,n}
Create Date: ${create_date}

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
${imports if imports else ""}

# revision identifiers, used by Alembic.
revision: str = ${repr(up_revision)}
down_revision: Union[str, None] = ${repr(down_revision)}
branch_labels: Union[str, Sequence[str], None] = ${repr(branch_labels)}
depends_on: Union[str, Sequence[str], None] = ${repr(depends_on)}


def upgrade() -> None:
    ${upgrades if upgrades else "pass"}


def downgrade() -> None:
    ${downgrades if downgrades else "pass"}
```

**Step 4: Create alembic/env.py**

```python
"""Alembic environment configuration."""

import asyncio
from logging.config import fileConfig

from sqlalchemy import pool
from sqlalchemy.engine import Connection
from sqlalchemy.ext.asyncio import async_engine_from_config

from alembic import context

from groundwork.core.config import get_settings
from groundwork.core.database import Base

# this is the Alembic Config object
config = context.config

# Interpret the config file for Python logging
if config.config_file_name is not None:
    fileConfig(config.config_file_name)

# Add your model's MetaData object here for 'autogenerate' support
target_metadata = Base.metadata

# Get database URL from settings
settings = get_settings()
config.set_main_option("sqlalchemy.url", str(settings.database_url))


def run_migrations_offline() -> None:
    """Run migrations in 'offline' mode."""
    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
    )

    with context.begin_transaction():
        context.run_migrations()


def do_run_migrations(connection: Connection) -> None:
    """Run migrations with connection."""
    context.configure(connection=connection, target_metadata=target_metadata)

    with context.begin_transaction():
        context.run_migrations()


async def run_async_migrations() -> None:
    """Run migrations in async mode."""
    connectable = async_engine_from_config(
        config.get_section(config.config_ini_section, {}),
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )

    async with connectable.connect() as connection:
        await connection.run_sync(do_run_migrations)

    await connectable.dispose()


def run_migrations_online() -> None:
    """Run migrations in 'online' mode."""
    asyncio.run(run_async_migrations())


if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()
```

**Step 5: Commit**

```bash
git add alembic.ini alembic/
git commit -m "feat: add Alembic migration infrastructure"
```

---

## Task 9: Docker Setup

**Files:**
- Create: `docker/Dockerfile`
- Create: `docker/docker-compose.yml`

**Step 1: Create docker directory**

Run: `mkdir -p docker`

**Step 2: Create Dockerfile**

Create `docker/Dockerfile`:
```dockerfile
FROM python:3.12-slim AS base

ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    UV_SYSTEM_PYTHON=1

WORKDIR /app

# Install uv
RUN pip install uv

# Dependencies layer (cached unless pyproject.toml changes)
COPY pyproject.toml uv.lock ./
RUN uv sync --frozen --no-dev

# Production image
FROM base AS production
COPY src/ ./src/
COPY alembic/ ./alembic/
COPY alembic.ini ./
EXPOSE 8000
CMD ["uv", "run", "uvicorn", "groundwork.main:app", "--host", "0.0.0.0", "--port", "8000"]

# Development image
FROM base AS development
RUN uv sync --frozen
EXPOSE 8000
CMD ["uv", "run", "uvicorn", "groundwork.main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]
```

**Step 3: Create docker-compose.yml**

Create `docker/docker-compose.yml`:
```yaml
services:
  db:
    image: postgres:16
    environment:
      POSTGRES_USER: groundwork
      POSTGRES_PASSWORD: groundwork
      POSTGRES_DB: groundwork
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U groundwork"]
      interval: 5s
      timeout: 5s
      retries: 5

  app:
    build:
      context: ..
      dockerfile: docker/Dockerfile
      target: development
    volumes:
      - ../src:/app/src
      - ../tests:/app/tests
      - ../alembic:/app/alembic
    ports:
      - "8000:8000"
    depends_on:
      db:
        condition: service_healthy
    env_file:
      - ../.env

volumes:
  postgres_data:
```

**Step 4: Create .env file for local development**

Run: `cp .env.example .env`

**Step 5: Commit**

```bash
git add docker/
git commit -m "feat: add Docker setup with hot-reload development"
```

---

## Task 10: Pre-commit Hooks

**Files:**
- Create: `.pre-commit-config.yaml`

**Step 1: Create pre-commit config**

Create `.pre-commit-config.yaml`:
```yaml
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v5.0.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
      - id: check-added-large-files
        args: ['--maxkb=1000']
      - id: check-merge-conflict
      - id: detect-private-key

  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.9.0
    hooks:
      - id: ruff
        args: [--fix]
      - id: ruff-format

  - repo: local
    hooks:
      - id: mypy
        name: mypy
        entry: uv run mypy src
        language: system
        types: [python]
        pass_filenames: false
```

**Step 2: Install pre-commit hooks**

Run: `uv run pre-commit install`
Expected: pre-commit installed at .git/hooks/pre-commit

**Step 3: Run pre-commit on all files**

Run: `uv run pre-commit run --all-files`
Expected: All checks pass

**Step 4: Commit**

```bash
git add .pre-commit-config.yaml
git commit -m "feat: add pre-commit hooks with Ruff and mypy"
```

---

## Task 11: CI/CD Pipeline

**Files:**
- Create: `.github/workflows/ci.yml`

**Step 1: Create GitHub workflows directory**

Run: `mkdir -p .github/workflows`

**Step 2: Create CI workflow**

Create `.github/workflows/ci.yml`:
```yaml
name: CI

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: astral-sh/setup-uv@v4
      - run: uv sync --frozen
      - run: uv run ruff check src tests
      - run: uv run ruff format --check src tests

  typecheck:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: astral-sh/setup-uv@v4
      - run: uv sync --frozen
      - run: uv run mypy src

  test:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:16
        env:
          POSTGRES_USER: groundwork
          POSTGRES_PASSWORD: groundwork
          POSTGRES_DB: groundwork_test
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    steps:
      - uses: actions/checkout@v4
      - uses: astral-sh/setup-uv@v4
      - run: uv sync --frozen
      - run: uv run pytest --cov=src --cov-report=xml
        env:
          DATABASE_URL: postgresql+asyncpg://groundwork:groundwork@localhost:5432/groundwork_test
          SECRET_KEY: test-secret-key
      - uses: codecov/codecov-action@v4
        with:
          files: coverage.xml
        if: always()

  build:
    needs: [lint, typecheck, test]
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    permissions:
      contents: read
      packages: write
    steps:
      - uses: actions/checkout@v4
      - uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
      - uses: docker/build-push-action@v5
        with:
          context: .
          file: docker/Dockerfile
          target: production
          push: true
          tags: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest
```

**Step 3: Commit**

```bash
git add .github/
git commit -m "feat: add CI/CD pipeline with GitHub Actions"
```

---

## Task 12: Test Fixtures

**Files:**
- Create: `tests/conftest.py`
- Create: `tests/factories/__init__.py`

**Step 1: Create test fixtures**

Create `tests/conftest.py`:
```python
"""Pytest configuration and fixtures."""

import os
from collections.abc import AsyncGenerator

import pytest
from httpx import ASGITransport, AsyncClient
from sqlalchemy.ext.asyncio import (
    AsyncSession,
    async_sessionmaker,
    create_async_engine,
)

# Set test environment before importing app
os.environ.setdefault("DATABASE_URL", "postgresql+asyncpg://groundwork:groundwork@localhost:5432/groundwork_test")
os.environ.setdefault("SECRET_KEY", "test-secret-key")
os.environ.setdefault("ENVIRONMENT", "testing")
os.environ.setdefault("DEBUG", "false")

from groundwork.core.config import get_settings
from groundwork.core.database import Base, get_db
from groundwork.main import create_app

# Clear settings cache to use test settings
get_settings.cache_clear()
settings = get_settings()

# Test database engine
test_engine = create_async_engine(
    str(settings.database_url),
    echo=False,
)
test_session_factory = async_sessionmaker(
    test_engine,
    class_=AsyncSession,
    expire_on_commit=False,
)


@pytest.fixture(scope="session")
def anyio_backend() -> str:
    """Use asyncio backend for pytest-asyncio."""
    return "asyncio"


@pytest.fixture(scope="session")
async def setup_database() -> AsyncGenerator[None, None]:
    """Create tables once per test session."""
    async with test_engine.begin() as conn:
        await conn.run_sync(Base.metadata.create_all)
    yield
    async with test_engine.begin() as conn:
        await conn.run_sync(Base.metadata.drop_all)


@pytest.fixture
async def db_session(setup_database: None) -> AsyncGenerator[AsyncSession, None]:
    """Transaction-wrapped session that rolls back after each test."""
    async with test_engine.connect() as conn:
        await conn.begin()
        async with test_session_factory(bind=conn) as session:
            yield session
        await conn.rollback()


@pytest.fixture
async def client(db_session: AsyncSession) -> AsyncGenerator[AsyncClient, None]:
    """Test client with overridden database dependency."""
    app = create_app()

    async def override_get_db() -> AsyncGenerator[AsyncSession, None]:
        yield db_session

    app.dependency_overrides[get_db] = override_get_db

    async with AsyncClient(
        transport=ASGITransport(app=app),
        base_url="http://test"
    ) as ac:
        yield ac
```

Create `tests/factories/__init__.py`:
```python
"""Factory Boy factories for test data generation."""
```

**Step 2: Run all tests**

Run: `uv run pytest -v`
Expected: All tests pass

**Step 3: Commit**

```bash
git add tests/conftest.py tests/factories/
git commit -m "feat: add test fixtures with transaction rollback"
```

---

## Task 13: Final Verification

**Step 1: Run linting**

Run: `uv run ruff check src tests`
Expected: No issues

**Step 2: Run formatting check**

Run: `uv run ruff format --check src tests`
Expected: All files formatted

**Step 3: Run type checking**

Run: `uv run mypy src`
Expected: Success

**Step 4: Run all tests with coverage**

Run: `uv run pytest --cov=src --cov-report=term-missing`
Expected: All tests pass, coverage > 80%

**Step 5: Verify Docker builds**

Run: `docker compose -f docker/docker-compose.yml build`
Expected: Build succeeds

**Step 6: Create final commit**

```bash
git add -A
git commit -m "chore: final verification and cleanup" --allow-empty
```

---

## Task 14: Merge to Main

**Step 1: Push feature branch**

Run: `git push -u origin feature/p0.1-infrastructure`
Expected: Branch pushed to remote

**Step 2: Create pull request or merge**

If using PR workflow:
```bash
gh pr create --title "feat: P0.1 Infrastructure Foundation" --body "..."
```

If merging directly:
```bash
git checkout main
git merge feature/p0.1-infrastructure
git push
```

---

## Summary

After completing all tasks, you will have:

- Project structure with src layout
- Configuration via environment variables
- Async PostgreSQL with SQLAlchemy 2.0
- Structured JSON logging
- Health check endpoints (/health/live, /health/ready, /health/details)
- FastAPI app factory with middleware
- Docker development environment with hot-reload
- Alembic migration infrastructure
- Pre-commit hooks (Ruff + mypy)
- Full CI/CD pipeline
- Test infrastructure with transaction rollback

**Total: 14 tasks, ~45 commits**
